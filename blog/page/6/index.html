<!doctype html>

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <!-- Bootstrap v4beta Imports -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">

    <style media="screen">
        body {
            padding-top: 70px;
            padding-bottom: 70px;
        }
    </style>

    
    

    <!-- Google Analytics -->
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-12498603-2', 'auto');
        ga('send', 'pageview');
    </script>

    <!-- ClustrMaps Tracking -->
    <!-- <script type="text/javascript" id="clstr_globe" src="//cdn.clustrmaps.com/globe.js?d=nhKoDpoTjWz4pC6CwI-fSy4hPoJ1uXwTLCfMCT3OK_8"></script> -->

    <!-- FontAwesome embed -->
    <!-- <script src="https://use.fontawesome.com/cb9dbe8e41.js"></script> -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" integrity="sha384-O8whS3fhG2OnA5Kas0Y9l3cfpmYjapjI0E4theH4iuMD+pLhbf6JI0jIMfYcK3yZ" crossorigin="anonymous">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/static/css/custom.css">
</head>

<title>Blog - Eric J. Ma's Personal Site</title>
<body class="body">
    <nav class="navbar navbar-expand-sm navbar-light fixed-top bg-light">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#local-links" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="local-links">
            <ul class="navbar-nav mr-auto">
                
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="fa fa-home" aria-hidden="true"></i> Home</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/resume"><i class="fa fa-file-text" aria-hidden="true"></i> Resume</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/blog"><i class="fa fa-rss" aria-hidden="true"></i> Blog</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/open-source"><i class="fa fa-code" aria-hidden="true"></i> Open Source</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/projects"><i class="fa fa-briefcase" aria-hidden="true"></i> Projects</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/talks"><i class="fa fa-microphone" aria-hidden="true"></i> Talks</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/teaching"><i class="fa fa-university" aria-hidden="true"></i> Teaching</a>
                </li>
                
            </ul>
        </div>
    </nav>
    <div class="container">
        
  
    
  <!-- Import stylesheet -->
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div>

  <!-- Set title style -->
  
    <h1><a href="../../../blog/2017/10/27/random-forests-a-good-default-model/">Random Forests: A Good Default Model?</a></h1>
  

  <!-- Append author -->
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2017-10-27
  
  </p>
  <!-- Append tags after author -->
  <p>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/data science/">
          data science
      </a>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/machine learning/">
          machine learning
      </a>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/random forest/">
          random forest
      </a>
      
  </p>
  

  <!-- Put post body -->
  <p>I've been giving this some thought, and wanted to go out on a limb to put forth this idea:</p>
<p><strong>I think Random Forests (RF) are a good "baseline" model to try, after establishing a "random" baseline case.</strong></p>
<p>(Clarification: I'm using RF as a shorthand for "forest-based ML algorithms", including XGBoost etc.)</p>
<p>Before I go on, let me first provide some setup.</p>
<p>Let's say we have a two-class classification problem. Assume everything is balanced. One "dumb baseline"" case is a coin flip. The other "dumb baseline" is predicting everything to be one class. Once we have these established, we can go to a "baseline" machine learning model.</p>
<p>Usually, people might say, "go do logistic regression (LR)" as your first baseline model for classification problems. It sure is a principled choice! Logistic regression is geared towards classification problems, makes only linear assumptions about the data, and identifies directional effects as well. From a practical perspective, it's also very fast to train.</p>
<p>But I've found myself more and more being oriented towards using RFs as my baseline model instead of logistic regression. Here are my reasons:</p>
<ol>
<li>Practically speaking, any modern computer can train a RF model with ~1000+ trees in not much more time than it would need for an LR model.</li>
<li>By using RFs, we do not make linearity assumptions about the data.</li>
<li>Additionally, we don't have to scale the data (one less thing to do).</li>
<li>RFs will automatically learn non-linear interaction terms in the data, which is not possible without further feature engineering in LR.</li>
<li>As such, the out-of-the-box performance using large RFs with default settings is often very good, making for a much more intellectually interesting challenge in trying to beat that classifier.</li>
<li>With <code>scikit-learn</code>, it's a one-liner change to swap out LR for RF. The API is what matters, and as such, drop-in replacements are easily implemented!</li>
</ol>
<p>Just to be clear, I'm not advocating for throwing away logistic regression altogether. There are moments where interpretability is needed, and is more easily done by using LR. In those cases, LR can be the "baseline model", or even just back-filled in after training the baseline RF model for comparison.</p>
<p>Random Forests were the darling of the machine learning world before neural networks came along, and even now, remain the tool-of-choice for colleagues in the cheminformatics world. Given how easy they are to use now, why not just start with them?</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../../../blog/2017/10/27/random-forests-a-good-default-model/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- Import stylesheet -->
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div>

  <!-- Set title style -->
  
    <h1><a href="../../../blog/2017/10/22/network-propagation/">Network Propagation</a></h1>
  

  <!-- Append author -->
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2017-10-22
  
  </p>
  <!-- Append tags after author -->
  <p>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/network science/">
          network science
      </a>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/graph theory/">
          graph theory
      </a>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/programming/">
          programming
      </a>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/python/">
          python
      </a>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/code snippets/">
          code snippets
      </a>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/data science/">
          data science
      </a>
      
  </p>
  

  <!-- Put post body -->
  <h2 id="introduction">Introduction</h2><p>I recently read a <a href="http://www.nature.com/nrg/journal/vaop/ncurrent/abs/nrg.2017.38.html">review paper on network propagation</a>. It looks like a very useful thing in data science, particularly where networks are involved, and I wanted to share it with everybody.</p>
<p>Before I go on, I will start off by assuming we have a dataset modelled as a "network", or a "graph", in which the nodes are entities in the graph, and edges are relationships between those entities. In the context of my work, I encounter biological networks of many kinds - gene-gene interactions, protein-protein interactions, protein-RNA interactions, evolutionary networks, and more.</p>
<p>What kind of problems can network propagation solve? The problem class generally follows this logic: I start with some nodes of interest, and I'm most interested in finding other nodes of interest based on these "seed" nodes. Knowing that path-based methods can often end up over-prioritizing highly connected nodes, we need a different principled method for finding these nodes. One way would be to take a random walk on the graph, and find out how often we land on a particular set of nodes on the graph. This random walk is what we call "network propagation".</p>
<h2 id="how-network-propagation-works">How network propagation works</h2><p>Network propagation follows this intuition: Imagine nodes contain information, and edges dictate which nodes information can be shared with. Network propagation shares the information with other nodes, according to the following rules:</p>
<ol>
<li>I can only share by copying to my neighbours in the graph,</li>
<li>I must share everything that I have with my neighbours, and</li>
<li>Exchanges in the graph happen simultaneously.</li>
</ol>
<p>An animation of how this works is shown below.</p>
<p>If you take my DataCamp course, you'll learn that networks can be represented as matrices on a computer. The adjacency matrix can be a 1/0 (i.e. binary) matrix that describes how nodes (rows and columns) are connected, and nodes can have their own vector of information (i.e. whether they are "seed" nodes or not). As it turns out, network propagation has a very nice matrix representation:</p>
<h2 id="how-to-implement-network-propagation">How to implement network propagation</h2><p>So, how do we do network propagation with NetworkX, <code>numpy</code> and Python? Let's take a look at code. Firstly, <strong>how do you convert a graph to a <code>numpy</code> matrix</strong>?</p>
<div class="hll"><pre><span></span><span class="c1"># Assume we have a graph G. Convert it to a numpy matrix.</span>
<span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">A</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">A</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
<span class="n">matrix</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]])</span>
</pre></div>
<p>This basically corresponds to the following graph:</p>
<p><img src="../../../blog/2017/10/22/network-propagation/graph.png" alt=""></p>
<p>Great! Now, let's mark out some "seed" nodes. These are the "nodes" of interest. To represent this, we use a binary vector - each slot in the vector represents one node in the graph. Let's start by highlighting two nodes, the second and third one:</p>
<div class="hll"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
<p>The <code>.reshape(A.shape[0], 1)</code> is done for convenience, so that each axis is aligned appropriately for the following matrix multiplication:</p>
<div class="hll"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="n">A</span> <span class="err">@</span> <span class="n">M</span>
<span class="n">matrix</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">]])</span>
</pre></div>
<p>After the end of one round, nodes 2 and 3 have no information held on them, but their neighbours do. Let's do two rounds of propagation, rather than just one.</p>
<div class="hll"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">5</span><span class="p">]:</span> <span class="n">A</span> <span class="err">@</span> <span class="p">(</span><span class="n">A</span> <span class="err">@</span> <span class="n">M</span><span class="p">)</span>
<span class="n">matrix</span><span class="p">([[</span> <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.</span><span class="p">]])</span>
</pre></div>
<p>After two rounds of information, information is shared back with the original nodes, but not necessarily evenly - it all depends on the connectivity of each node.</p>
<p>It'll get really verbose doing 100 rounds; imagine doing <code>A @ (A @ (A @ (A @ .....)))</code>. Instead of doing that, a recursive function may be better. At the same time, with many rounds of network propagation, we will end up with really large numbers. Therefore, it will be helpful to also normalize the result of matrix multiplication.</p>
<div class="hll"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">6</span><span class="p">]:</span> <span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
   <span class="o">...</span><span class="p">:</span>     <span class="k">return</span> <span class="n">arr</span> <span class="o">/</span> <span class="n">arr</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">7</span><span class="p">]:</span> <span class="k">def</span> <span class="nf">recursive_propagate</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
   <span class="o">...</span><span class="p">:</span>     <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
   <span class="o">...</span><span class="p">:</span>         <span class="k">return</span> <span class="n">recursive_propagate</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">normalize</span><span class="p">(</span><span class="n">A</span> <span class="err">@</span> <span class="n">M</span><span class="p">),</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
   <span class="o">...</span><span class="p">:</span>     <span class="k">else</span><span class="p">:</span>
   <span class="o">...</span><span class="p">:</span>         <span class="k">return</span> <span class="n">normalize</span><span class="p">(</span><span class="n">A</span> <span class="err">@</span> <span class="n">M</span><span class="p">)</span>
   <span class="o">...</span><span class="p">:</span>
</pre></div>
<p>On a previous blog post, I've alluded to the fact that recursive functions are pretty darn useful!</p>
<h2 id="result">Result</h2><p>So, let's take a look at the result of a few rounds of propagation.</p>
<p><img src="../../../blog/2017/10/22/network-propagation/figure_1_sm.png" alt=""></p>
<p>The first thing that I'd like to highlight is that the information propagation process converges on a final result fairly quickly. The second thing I'd like to highlight is that the purple nodes (there are two lines!), which weren't highlighted at the start, ended up having the highest propagation scores, followed by the red node.</p>
<p>For those who are familiar with Markov chains, I believe network propagation has strong parallels with that.</p>
<h2 id="conclusion">Conclusion</h2><p>Network propagation is conceptually simple, and easy to implement in Python.</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../../../blog/2017/10/22/network-propagation/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- Import stylesheet -->
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div>

  <!-- Set title style -->
  
    <h1><a href="../../../blog/2017/10/11/pypy-impressive/">PyPy: Impressive!</a></h1>
  

  <!-- Append author -->
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2017-10-11
  

  <!-- Put post body -->
  <p>A few years on after trying out PyPy for the first time and wrestling with it, I still find it to be pretty awesome.</p>
<p>Now that PyPy officially supports <code>numpy</code>, I'm going to profile a few simple statistical simulation tasks:</p>
<ul>
<li>Computing the mean of a number of random number draws.</li>
<li>Simulating many coin flips</li>
</ul>
<p>I'll profile each of the tasks four ways:</p>
<ul>
<li>Pure Python implementation running from the CPython and PyPy interpreters</li>
<li><code>numpy</code> implementation running from the CPython and PyPy interpreters.</li>
</ul>
<p>So, how do PyPy and CPython fare? Let's show the results up front first.</p>
<p><a href="../../../blog/2017/10/11/pypy-impressive/profile.png"><img src="../../../blog/2017/10/11/pypy-impressive/profile-sm.png" alt="Profiling results."></a></p>
<p>Click on the image to view a higher resolution chart. The raw recorded measurements can be found <a href="https://docs.google.com/spreadsheets/d/1QB1hF7Z8SGYjvll8sYCjVYEYAgzL4pjqGt1dbO6B2Co/edit?usp=sharing">on Google Sheets</a>.</p>
<p>Here's a description of what's happening:</p>
<ul>
<li>(top-left): PyPy is approx. 10X faster than CPython at computing the mean of 10 million random numbers.</li>
<li>(top-right): When both are running <code>numpy</code>, the speed is identical.</li>
<li>(bottom-left): When simulating coin flips, PyPy with a custom <code>binomial()</code> function is about 3X faster than CPython.</li>
<li>(bottom-right): When using <code>numpy</code> instead, there is a bottleneck, and PyPy fails badly compared to CPython.</li>
</ul>
<p>It's pretty clear that when PyPy is dealing with "pure" data (i.e. not having to pass data between Python and C), PyPy runs very, very fast, and, at least in the scenarios tested here, it performs faster than the CPython interpreter. This is consistent with my previous observations, and probably explains why PyPy is very good for code that is very repetitive; the JIT tracer really speeds things up.</p>
<p>That last plot (bottom-right) is a big curiosity. Using the code below, I measured the random number generation is actually just as fast as it should be using CPython, but that PyPy failed badly when I was passing in a <code>numpy</code> array to the <code>Counter()</code> object (from the standard library). I'm not sure what is happening behind-the-scenes, but I have reached out to the PyPy developers to ask what's going on, and will update this post at a later date.</p>
<p><strong>UPDATE:</strong> I heard back from the PyPy devs <a href="https://bitbucket.org/pypy/pypy/issues/2680/slow-speed-going-from-numpy-data-structure">on BitBucket</a>, and this is indeed explainable by data transfer between the C-to-PyPy interface. It's probably parallel to the latency that arises from transferring data between the CPU and GPU, or between compute nodes.</p>
<p>So, what does this mean? It means that for pure Python code, PyPy can be a very powerful way to accelerate your code. One example I can imagine is agent-based simulations using Python objects. Another example that comes to mind is running a web server that only ever deals with strings, floats and JSONs (in contrast to matrix-heavy scientific computing).</p>
<p>Now, for those who are curious, here's the source code for the <strong>pure Python implementation of the mean of random numbers</strong>.</p>
<div class="hll"><pre><span></span><span class="c1"># Mean of 10 million random number draws.</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">n</span> <span class="o">=</span> <span class="mf">1E7</span>
<span class="n">rnds</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">)):</span>
    <span class="n">rnds</span> <span class="o">+=</span> <span class="n">random</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">rnds</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;{} seconds&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>
<p>And here's the source code for the <strong><code>numpy</code> implementation of the mean of random numbers</strong>.</p>
<div class="hll"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1E7</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} seconds&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>
<p>Next, here's the source code for <strong>coin flips in pure Python</strong>:</p>
<div class="hll"><pre><span></span><span class="c1"># Simulate 10 million biased coin flips with p = 0.3</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">rnd</span> <span class="o">=</span> <span class="n">random</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">rnd</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">False</span>


<span class="n">p</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">1E7</span><span class="p">))]</span>
<span class="k">print</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">result</span><span class="p">))</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} seconds&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>
<p>And finally, source code for <strong>coin flips using <code>numpy</code></strong>:</p>
<div class="hll"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">binomial</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">coinflips</span> <span class="o">=</span> <span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1E7</span><span class="p">))</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Time for numpy coinflips: {} seconds&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">coinflips</span><span class="p">))</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} seconds&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../../../blog/2017/10/11/pypy-impressive/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- Import stylesheet -->
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div>

  <!-- Set title style -->
  
    <h1><a href="../../../blog/2017/10/10/pydata-nyc-2017/">PyData NYC 2017</a></h1>
  

  <!-- Append author -->
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2017-10-10
  
  </p>
  <!-- Append tags after author -->
  <p>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/pydata/">
          pydata
      </a>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/conferences/">
          conferences
      </a>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/python/">
          python
      </a>
      
  </p>
  

  <!-- Put post body -->
  <p>I'm seriously looking forward to PyData NYC this year -- there's a great lineup of talks that I'm particularly looking forward to hearing! The theme for my set of must-see talks this year is "Bayesian machine learning" - there's much for me to learn!</p>
<p>The first is by my fellow Boston Bayesian <strong><a href="https://colindcarroll.com/">Colin Caroll</a></strong> with his talk titled <a href="https://pydata.org/nyc2017/schedule/presentation/12/">Two views on regression with PyMC3 and scikit-learn</a>. Colin is a mathematician at heart, even though he does software engineering for living now, and I can't wait to hear about regularization strategies!</p>
<p>The second is by <strong><a href="https://pydata.org/nyc2017/speaker/profile/6/">Nicole Carlson</a></strong>, with her talk titled <a href="https://pydata.org/nyc2017/schedule/presentation/24/">Turning PyMC3 into scikit-learn</a>. Nicole's talk is of interest to me because I've implemented models in PyMC3 before, and now would like to know how to make them reusable!</p>
<p>The third talk is by <strong><a href="https://pydata.org/nyc2017/speaker/profile/118/">Chaya Stern</a></strong>, with her talk titled <a href="https://pydata.org/nyc2017/schedule/presentation/53/">Bayesian inference in computational chemistry</a>. Super relevant to my work at Novartis!</p>
<p>The fourth is by my fellow Boston Pythonista <strong><a href="https://pydata.org/nyc2017/speaker/profile/34/">Joe Jevnik</a></strong>, who will be speaking on the first day about his journey into deep learning on some really cool time-series data. He works at Quantopian, BUT the spoiler here is that his talk is NOT about financial data! (I've heard his talk outline already.)</p>
<p>The fifth is a tutorial by <strong><a href="https://pydata.org/nyc2017/speaker/profile/29/">Jacob Schrieber</a></strong>, with his talk titled <a href="https://pydata.org/nyc2017/schedule/presentation/30/">pomegranate: fast and flexible probabilistic modeling in python</a>. <code>pomegranate</code>'s API models after the <code>scikit-learn</code>'s API; with the API being the user-facing interface, and <code>scikit-learn</code> being the <em>de facto</em> go-to library for machine learning, I'd be interested to see how much more <code>pomegranate</code> adds to the ecosystem, particularly w.r.t. Bayesian models.</p>
<p>There are a swathe of other good talks that I'm expecting to be able to catch online later on. <strong><a href="https://matthewrocklin.com/">Matt Rocklin</a></strong>, who is the lead developer of Dask, has done a ton of work on speeding Python up through parallelism. His talk will be on <a href="https://pydata.org/nyc2017/schedule/presentation/22/">the use of Cython &amp; Dask to speed up GeoPandas</a>.</p>
<p>Also, <strong><a href="https://pydata.org/nyc2017/speaker/profile/80/">Thomas Caswell</a></strong>, one of the <a href="http://matplotlib.org/"><code>matplotlib</code></a> lead devs who helped guide my first foray into open source contributions, is giving a tutorial on <a href="https://pydata.org/nyc2017/schedule/presentation/3/">developing interactive figures in matplotlib</a>. Highly recommended if you're into the visualization world!</p>
<p>Finally, the always-interesting, always entertaining <strong><a href="https://pydata.org/nyc2017/schedule/presentation/25/">en zyme</a></strong> will be speaking on an <a href="https://pydata.org/nyc2017/schedule/presentation/25/">interesting topic</a>.</p>
<p>Looking forward to being at the conference, and meeting old and new friends there!</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../../../blog/2017/10/10/pydata-nyc-2017/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- Import stylesheet -->
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div>

  <!-- Set title style -->
  
    <h1><a href="../../../blog/2017/10/10/recursive-programming-and-dags/">Recursive Programming and DAGs</a></h1>
  

  <!-- Append author -->
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2017-10-10
  
  </p>
  <!-- Append tags after author -->
  <p>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/programming/">
          programming
      </a>
      <i class="fas fa-tag"></i>
      <a href="../../../blog/tag/code snippets/">
          code snippets
      </a>
      
  </p>
  

  <!-- Put post body -->
  <p>Over the past few days, I've found myself using recursive programming to implement a "model specification" system with inheritance for deep learning. The goal here is to enable reproducible computational experiments for particular deep learning hyperparameter sets. Reproducibility is something I learned from the Software/Data Carpentry initiative, thus I wanted to ensure that my own work was reproducible, even if it's not (because of corporate reasons) open-able, because it's the right thing to do.</p>
<p>So, how do these "model spec" files work? I call them "experiment profiles", and they specify a bunch of things: <strong>model architecture</strong>, <strong>training parameters</strong>, and <strong>data tasks</strong>. These experiment profiles are stored in YAML files on disk. A profile essentially looks like the following (dummy examples provided, naturally):</p>
<div class="hll"><pre><span></span><span class="c1"># Name: default.yaml</span>
<span class="l l-Scalar l-Scalar-Plain">parent</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="l l-Scalar l-Scalar-Plain">data_tasks</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">tasks</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">task1</span><span class="p p-Indicator">,</span> <span class="nv">task2</span><span class="p p-Indicator">,</span> <span class="nv">task3</span><span class="p p-Indicator">]</span>
<span class="l l-Scalar l-Scalar-Plain">model_architecture</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">hidden_layers</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">20</span><span class="p p-Indicator">,</span> <span class="nv">20</span><span class="p p-Indicator">,</span> <span class="nv">20</span><span class="p p-Indicator">]</span>
    <span class="l l-Scalar l-Scalar-Plain">hidden_dropouts</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">0.1</span><span class="p p-Indicator">,</span> <span class="nv">0.2</span><span class="p p-Indicator">,</span> <span class="nv">0.3</span><span class="p p-Indicator">]</span>
<span class="l l-Scalar l-Scalar-Plain">training_parameters</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">optimizer</span><span class="p p-Indicator">:</span> <span class="s">&quot;sgd&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">optimizer_options</span><span class="p p-Indicator">:</span>
        <span class="l l-Scalar l-Scalar-Plain">n_epochs</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
</pre></div>
<p>In this YAML file, the key-value pairs essentially match the API of the tooling I've built on top of Keras' API to make myself more productive. (From the example, it should be clear that we're dealing with only feed-forward neural networks and nothing else more complicated.) The key here (pun unintended) is that I have a <code>parent</code> key-value pair that specifies another experiment profile that I can inherit from.</p>
<p>Let's call the above example <code>default.yaml</code>. Let's say I want to run another computational experiment that uses the <code>adam</code> optimizer instead of plain vanilla <code>sgd</code>. Instead of re-specifying the entire YAML file, by implementing an inheritance scheme, I can re-specify only the optimizer and optimizer_options.</p>
<div class="hll"><pre><span></span><span class="c1"># Name: adam.yaml</span>
<span class="l l-Scalar l-Scalar-Plain">parent</span><span class="p p-Indicator">:</span> <span class="s">&quot;default.yaml&quot;</span>
<span class="l l-Scalar l-Scalar-Plain">training_parameters</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">optimizer</span><span class="p p-Indicator">:</span> <span class="s">&quot;adam&quot;</span>
</pre></div>
<p>Finally, let's say I find out that 20 epochs (inherited from <code>default.yaml</code>) is too much for Adam - after all, Adam is one of the most efficient gradient descent algorithms out there - and I want to change it to 3 epochs instead. I can do the following:</p>
<div class="hll"><pre><span></span><span class="c1"># Name: adam-3.yaml</span>
<span class="l l-Scalar l-Scalar-Plain">parent</span><span class="p p-Indicator">:</span> <span class="s">&quot;adam.yaml&quot;</span>
<span class="l l-Scalar l-Scalar-Plain">training_parameters</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">optimizer_options</span><span class="p p-Indicator">:</span>
        <span class="l l-Scalar l-Scalar-Plain">n_epochs</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
</pre></div>
<p>Okay, so specifying YAML files with inheritance is all good, but how do I ensure that I get the entire parameter set out correctly, without writing verbose code? This is where the power of recursive programming comes in. Using recursion, I can solve this problem with <strong>a single function that calls itself on one condition, and returns a result on another condition</strong>. That's a recursive function in its essence.</p>
<p>The core of this problem is traversing the inheritance path, from <code>adam-3.yaml</code> to <code>adam.yaml</code> to <code>default.yaml</code>. Once I have the inheritance path specified, loading the YAML files as a dictionary becomes the easy part.</p>
<p>How would this look like in code? Let's take a look at an implementation.</p>
<div class="hll"><pre><span></span><span class="kn">import</span> <span class="nn">yaml</span>

<span class="k">def</span> <span class="nf">inheritance_path</span><span class="p">(</span><span class="n">yaml_file</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :param str yaml_file: The path to the yaml file of interest.</span>
<span class="sd">    :param list path: A list specifying the existing inheritance path. First</span>
<span class="sd">        entry is the file of interest, and parents are recursively appended to</span>
<span class="sd">        the end of the list.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">yaml_file</span><span class="p">,</span> <span class="s1">&#39;r+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">p</span><span class="p">[</span><span class="s1">&#39;parent&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">path</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;parent&#39;</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">inheritance_path</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;parent&#39;</span><span class="p">],</span> <span class="n">path</span><span class="p">)</span>
</pre></div>
<p>The most important part of the function is in the <code>if</code>/<code>else</code> block. If I have reached the "root" of the inheritance path, (that is, I have hit <code>default.yaml</code> which has no parent), then I return the <code>path</code> traversed. Otherwise, I return into the <code>inheritance_path</code> function call again, but with an updated <code>path</code> list, and a different <code>yaml_file</code> to read. It's a bit like doing a <code>while</code> loop, but in my opinion, a bit more elegant aesthetically.</p>
<p>Once I've gotten the path list, I can finally load the parameters using a single function that calls on <code>inheritance_path</code>.</p>
<div class="hll"><pre><span></span><span class="k">def</span> <span class="nf">load_params</span><span class="p">(</span><span class="n">yaml_file</span><span class="p">):</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">inheritance_path</span><span class="p">(</span><span class="n">yaml_file</span><span class="p">,</span> <span class="p">[</span><span class="n">yaml_file</span><span class="p">])</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">data_tasks</span><span class="o">=</span><span class="nb">dict</span><span class="p">(),</span>
             <span class="n">model_architecture</span><span class="o">=</span><span class="nb">dict</span><span class="p">(),</span>
             <span class="n">training_parameters</span><span class="o">=</span><span class="nb">dict</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">path</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>  <span class="c1"># go in reverse!</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s1">&#39;r+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">yaml</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">p</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span>
</pre></div>
<p>This is the equivalent of traversing a Directed Acyclic Graph (DAG), or in some special cases, a tree data structure, but in a way where we don't have to know the entire tree structure ahead of time. The goal is to reach the root from any node:</p>
<pre><code>root
    |- A
        |- B
        |- C
            |- D
            |- E
    |- F
        |- G
        |- H
        |- I
            |- J
</code></pre>
<p>Also, because we only have one pointer in each YAML file to its parent, we have effectively created a "Linked List" that we can use to trace a path back to the "root" node, along the way collecting the information that we need together. By using this method of traversal, we only need to know the neighbors, and at some point (however long it takes), we will reach the root.</p>
<pre><code>D -&gt; C -&gt; A -&gt; root
E -&gt; C -&gt; A -&gt; root
J -&gt; I -&gt; F -&gt; root
</code></pre>
<p>If you were wondering why linked lists, trees and other data structures might be useful as a data scientist, I hope this illustrates on productive example!</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../../../blog/2017/10/10/recursive-programming-and-dags/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  

  
  <div class="pagination">
    
      <a href="../../../blog/page/5/">&laquo; Previous</a>
    
    | 6 |
    
      <a href="../../../blog/page/7/">Next &raquo;</a>
    
  </div>


    </div>

    <nav class="navbar navbar-expand-sm navbar-light fixed-bottom bg-light">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#external-links" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="external-links">
            <ul class="navbar-nav mr-auto">
                
                <li class="nav-item">
                    <a class="nav-link" href="https://www.linkedin.com/in/ericmjl"><i class="fab fa-linkedin" aria-hidden="true"></i> LinkedIn</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://twitter.com/ericmjl"><i class="fab fa-twitter" aria-hidden="true"></i> Twitter</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://github.com/ericmjl"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://stackoverflow.com/users/1274908/ericmjl"><i class="fab fa-stack-overflow" aria-hidden="true"></i> Stack Overflow</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://shortwhale.com/ericmjl"><i class="far fa-envelope" aria-hidden="true"></i> Contact Me</a>
                </li>
                
            </ul>
        </div>
    </nav>
    <!-- Boostrap JS imports -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>

</body>
